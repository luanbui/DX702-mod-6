{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e97a31d",
   "metadata": {},
   "source": [
    "# Fixed Effects Regression Analysis\n",
    "## Coding Quiz 2\n",
    "\n",
    "**Task**: Do a regression to estimate the fixed effect of each group. We assume that there is one single linear coefficient for all the data, plus the fixed effect of each group.\n",
    "\n",
    "**Dataset**: homework_2.1.csv\n",
    "- **time**: Treatment variable (continuous)\n",
    "- **G1, G2, G3**: Outcomes for three different groups\n",
    "\n",
    "**Model**: For each group i, we estimate:\n",
    "$$Y_i = \\beta_0 + \\beta_1 \\cdot \\text{time} + \\alpha_i + \\epsilon$$\n",
    "\n",
    "Where:\n",
    "- $\\beta_1$ is the common slope (effect of time) across all groups\n",
    "- $\\alpha_i$ is the fixed effect for group i (intercept adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a0b74b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c4522b",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b1d977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (100, 4)\n",
      "\n",
      "First 10 rows:\n",
      "   time        G1        G2        G3\n",
      "0     0  0.882026  1.441575  0.065409\n",
      "1     1  0.210079 -0.163880  0.140310\n",
      "2     2  0.509369 -0.115242  0.819830\n",
      "3     3  1.150447  1.014698  0.607632\n",
      "4     4  0.973779 -0.046562  0.610066\n",
      "5     5 -0.438639  1.521811 -0.508478\n",
      "6     6  0.535044  0.353191  0.297837\n",
      "7     7 -0.005679  0.196273 -0.049015\n",
      "8     8  0.028391  1.541471  0.469962\n",
      "9     9  0.295299  1.330257  0.290925\n",
      "\n",
      "Basic statistics:\n",
      "             time          G1          G2          G3\n",
      "count  100.000000  100.000000  100.000000  100.000000\n",
      "mean    49.500000    0.524904    1.036006    0.715384\n",
      "std     29.011492    0.561614    0.552593    0.581227\n",
      "min      0.000000   -1.076495   -0.163880   -0.508478\n",
      "25%     24.750000    0.186046    0.621088    0.298386\n",
      "50%     49.500000    0.464842    1.006778    0.643041\n",
      "75%     74.250000    0.947191    1.427074    1.125461\n",
      "max     99.000000    1.862935    2.561618    2.321958\n",
      "\n",
      "Data types:\n",
      "time      int64\n",
      "G1      float64\n",
      "G2      float64\n",
      "G3      float64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      "time    0\n",
      "G1      0\n",
      "G2      0\n",
      "G3      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('homework_2.1.csv')\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "print(df.head(10))\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a74b370",
   "metadata": {},
   "source": [
    "## 2. Reshape Data for Fixed Effects Analysis\n",
    "\n",
    "We need to convert the data from wide format (G1, G2, G3 as separate columns) to long format where we have:\n",
    "- One column for the outcome (Y)\n",
    "- One column identifying the group\n",
    "- The time variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b166327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape from wide to long format\n",
    "df_long = pd.melt(df, id_vars=['time'], value_vars=['G1', 'G2', 'G3'],\n",
    "                  var_name='group', value_name='outcome')\n",
    "\n",
    "print(\"Reshaped data (long format):\")\n",
    "print(df_long.head(15))\n",
    "print(f\"\\nTotal observations: {len(df_long)}\")\n",
    "print(f\"Observations per group: {df_long.groupby('group').size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4aad36",
   "metadata": {},
   "source": [
    "## 3. Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dfd72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outcomes over time for each group\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for group in ['G1', 'G2', 'G3']:\n",
    "    plt.plot(df['time'], df[group], 'o-', label=group, alpha=0.7, linewidth=2)\n",
    "\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Outcome', fontsize=12)\n",
    "plt.title('Outcomes Over Time for Each Group', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: Each group has a different baseline level but may share\")\n",
    "print(\"a common time trend. Fixed effects will capture these group differences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23217f6d",
   "metadata": {},
   "source": [
    "## 4. Fixed Effects Regression Using Statsmodels\n",
    "\n",
    "We'll use the formula API to estimate:\n",
    "$$\\text{outcome} = \\beta_1 \\cdot \\text{time} + \\alpha_{\\text{G1}} + \\alpha_{\\text{G2}} + \\alpha_{\\text{G3}} + \\epsilon$$\n",
    "\n",
    "The `C(group)` notation creates dummy variables for each group (fixed effects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a697b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed effects regression with statsmodels\n",
    "# Model: outcome ~ time + C(group)\n",
    "# C(group) creates dummy variables for fixed effects\n",
    "\n",
    "model = ols('outcome ~ time + C(group)', data=df_long).fit()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FIXED EFFECTS REGRESSION RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(model.summary())\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a34a071",
   "metadata": {},
   "source": [
    "## 5. Extract and Interpret the Fixed Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5db693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients\n",
    "coefficients = model.params\n",
    "time_effect = coefficients['time']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXTRACTED COEFFICIENTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nCommon Time Effect (β₁): {time_effect:.6f}\")\n",
    "print(\"\\nFixed Effects (Group-specific intercepts):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# The baseline group (G1) is absorbed in the intercept\n",
    "# Other groups show their difference from G1\n",
    "intercept = coefficients['Intercept']\n",
    "print(f\"Group G1 fixed effect (α₁): {intercept:.6f}\")\n",
    "\n",
    "# Extract fixed effects for G2 and G3 relative to G1\n",
    "if 'C(group)[T.G2]' in coefficients:\n",
    "    g2_effect = intercept + coefficients['C(group)[T.G2]']\n",
    "    print(f\"Group G2 fixed effect (α₂): {g2_effect:.6f}\")\n",
    "    \n",
    "if 'C(group)[T.G3]' in coefficients:\n",
    "    g3_effect = intercept + coefficients['C(group)[T.G3]']\n",
    "    print(f\"Group G3 fixed effect (α₃): {g3_effect:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n• The effect of time is {time_effect:.6f} units per time period\")\n",
    "print(\"  (This is the SAME for all groups)\")\n",
    "print(\"\\n• Fixed effects represent baseline differences between groups:\")\n",
    "print(\"  - They capture time-invariant group characteristics\")\n",
    "print(\"  - Each group has its own intercept\")\n",
    "print(\"\\n• By including fixed effects, we control for unobserved differences\")\n",
    "print(\"  between groups and isolate the true effect of time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67cd133",
   "metadata": {},
   "source": [
    "## 6. Visualize Fixed Effects Regression Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe2210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot actual data with fitted lines\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Subplot 1: Actual data with fitted lines\n",
    "plt.subplot(1, 2, 1)\n",
    "colors = {'G1': 'blue', 'G2': 'red', 'G3': 'green'}\n",
    "\n",
    "for group in ['G1', 'G2', 'G3']:\n",
    "    group_data = df_long[df_long['group'] == group]\n",
    "    plt.scatter(group_data['time'], group_data['outcome'], \n",
    "               alpha=0.5, label=f'{group} (actual)', color=colors[group])\n",
    "    \n",
    "    # Plot fitted line for each group\n",
    "    time_range = np.linspace(df_long['time'].min(), df_long['time'].max(), 100)\n",
    "    if group == 'G1':\n",
    "        fitted = intercept + time_effect * time_range\n",
    "    elif group == 'G2':\n",
    "        fitted = g2_effect + time_effect * time_range\n",
    "    else:  # G3\n",
    "        fitted = g3_effect + time_effect * time_range\n",
    "    \n",
    "    plt.plot(time_range, fitted, '--', linewidth=2.5, \n",
    "            label=f'{group} (fitted)', color=colors[group])\n",
    "\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Outcome', fontsize=12)\n",
    "plt.title('Fixed Effects Regression:\\nActual vs Fitted Values', fontsize=14)\n",
    "plt.legend(fontsize=9, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Fixed effects comparison\n",
    "plt.subplot(1, 2, 2)\n",
    "groups = ['G1', 'G2', 'G3']\n",
    "fixed_effects = [intercept, g2_effect, g3_effect]\n",
    "colors_bar = ['blue', 'red', 'green']\n",
    "\n",
    "plt.bar(groups, fixed_effects, color=colors_bar, alpha=0.7, edgecolor='black')\n",
    "plt.xlabel('Group', fontsize=12)\n",
    "plt.ylabel('Fixed Effect (Intercept)', fontsize=12)\n",
    "plt.title('Group-Specific Fixed Effects\\n(Baseline Differences)', fontsize=14)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (group, effect) in enumerate(zip(groups, fixed_effects)):\n",
    "    plt.text(i, effect + 0.02, f'{effect:.3f}', \n",
    "            ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nNote: All three groups have the SAME slope ({time_effect:.6f})\")\n",
    "print(\"but DIFFERENT intercepts (fixed effects).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe5b4c0",
   "metadata": {},
   "source": [
    "## 7. Alternative Method: Manual Calculation with Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdecf1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables manually\n",
    "df_long['G1_dummy'] = (df_long['group'] == 'G1').astype(int)\n",
    "df_long['G2_dummy'] = (df_long['group'] == 'G2').astype(int)\n",
    "df_long['G3_dummy'] = (df_long['group'] == 'G3').astype(int)\n",
    "\n",
    "# Use sklearn LinearRegression (drop one dummy to avoid multicollinearity)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_manual = df_long[['time', 'G2_dummy', 'G3_dummy']]\n",
    "y_manual = df_long['outcome']\n",
    "\n",
    "manual_model = LinearRegression(fit_intercept=True)\n",
    "manual_model.fit(X_manual, y_manual)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MANUAL CALCULATION USING SKLEARN\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nIntercept (G1 fixed effect): {manual_model.intercept_:.6f}\")\n",
    "print(f\"Coefficient for time: {manual_model.coef_[0]:.6f}\")\n",
    "print(f\"Coefficient for G2 dummy: {manual_model.coef_[1]:.6f}\")\n",
    "print(f\"Coefficient for G3 dummy: {manual_model.coef_[2]:.6f}\")\n",
    "\n",
    "print(f\"\\nFixed effects:\")\n",
    "print(f\"  G1: {manual_model.intercept_:.6f}\")\n",
    "print(f\"  G2: {manual_model.intercept_ + manual_model.coef_[1]:.6f}\")\n",
    "print(f\"  G3: {manual_model.intercept_ + manual_model.coef_[2]:.6f}\")\n",
    "\n",
    "print(\"\\n✓ These match the statsmodels results!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7c811c",
   "metadata": {},
   "source": [
    "## 8. Summary and Key Takeaways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6969a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"FIXED EFFECTS REGRESSION - SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n📊 MODEL: outcome = β₁·time + αᵢ + ε\")\n",
    "print(f\"\\nwhere:\")\n",
    "print(f\"  • β₁ = {time_effect:.6f} (common time effect for all groups)\")\n",
    "print(f\"  • α₁ = {intercept:.6f} (fixed effect for Group 1)\")\n",
    "print(f\"  • α₂ = {g2_effect:.6f} (fixed effect for Group 2)\")\n",
    "print(f\"  • α₃ = {g3_effect:.6f} (fixed effect for Group 3)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY CONCEPTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "1. FIXED EFFECTS capture time-invariant differences between groups\n",
    "   - Each group has its own baseline (intercept)\n",
    "   - Controls for unobserved heterogeneity\n",
    "\n",
    "2. COMMON SLOPE assumption\n",
    "   - All groups experience the same effect of time\n",
    "   - Only the starting point (intercept) differs\n",
    "\n",
    "3. WHY USE FIXED EFFECTS?\n",
    "   - Removes bias from group-specific characteristics\n",
    "   - Focuses on within-group changes over time\n",
    "   - Isolates the causal effect of the treatment (time)\n",
    "\n",
    "4. REAL-WORLD APPLICATIONS\n",
    "   - Panel data analysis (individuals/firms over time)\n",
    "   - Difference-in-differences estimation\n",
    "   - Controlling for unmeasured confounders\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"✓ R-squared: {model.rsquared:.4f}\")\n",
    "print(f\"✓ Adjusted R-squared: {model.rsquared_adj:.4f}\")\n",
    "print(f\"✓ Number of observations: {len(df_long)}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41791d0",
   "metadata": {},
   "source": [
    "# Bootstrap Simulation Analysis\n",
    "## Questions 3-5: Exploring Different Possibilities\n",
    "\n",
    "**Task**: Given a data set, create a bootstrap simulation to try different possibilities.\n",
    "\n",
    "**Dataset**: homework_2.2.csv\n",
    "- **X**: Binary treatment variable (0 or 1)\n",
    "- **Y**: Continuous outcome variable\n",
    "- **Z**: Another continuous variable\n",
    "\n",
    "**Goal**: Use bootstrap resampling to:\n",
    "1. Estimate statistics with confidence intervals\n",
    "2. Test different hypotheses about the data\n",
    "3. Understand sampling variability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac0616",
   "metadata": {},
   "source": [
    "## 9. Load Bootstrap Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fe44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bootstrap dataset\n",
    "df_boot = pd.read_csv('homework_2.2.csv')\n",
    "\n",
    "print(\"Bootstrap Dataset Information:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Shape: {df_boot.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "print(df_boot.head(10))\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df_boot.describe())\n",
    "print(f\"\\nValue counts for X (treatment):\")\n",
    "print(df_boot['X'].value_counts().sort_index())\n",
    "print(f\"\\nCorrelations:\")\n",
    "print(df_boot.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c106b2",
   "metadata": {},
   "source": [
    "## 10. Bootstrap Function: Resampling with Replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da58fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_sample(data, n_bootstrap=1000, statistic_func=np.mean, random_seed=42):\n",
    "    \"\"\"\n",
    "    Perform bootstrap resampling and calculate a statistic.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        The original data to bootstrap\n",
    "    n_bootstrap : int\n",
    "        Number of bootstrap samples to generate\n",
    "    statistic_func : function\n",
    "        Function to calculate the statistic (e.g., np.mean, np.median)\n",
    "    random_seed : int\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bootstrap_stats : array\n",
    "        Array of statistics from each bootstrap sample\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    n = len(data)\n",
    "    bootstrap_stats = []\n",
    "    \n",
    "    for i in range(n_bootstrap):\n",
    "        # Resample with replacement\n",
    "        sample = np.random.choice(data, size=n, replace=True)\n",
    "        # Calculate statistic\n",
    "        stat = statistic_func(sample)\n",
    "        bootstrap_stats.append(stat)\n",
    "    \n",
    "    return np.array(bootstrap_stats)\n",
    "\n",
    "print(\"✓ Bootstrap function defined\")\n",
    "print(\"\\nThis function will:\")\n",
    "print(\"  1. Create n_bootstrap samples by randomly selecting observations with replacement\")\n",
    "print(\"  2. Calculate a statistic (mean, median, etc.) for each sample\")\n",
    "print(\"  3. Return all statistics to form a bootstrap distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97865c93",
   "metadata": {},
   "source": [
    "## 11. Bootstrap Simulation: Treatment Effect Estimation\n",
    "\n",
    "We'll estimate the Average Treatment Effect (ATE) using bootstrap to understand uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245a4890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap for treatment effect\n",
    "np.random.seed(42)\n",
    "n_bootstrap = 10000\n",
    "\n",
    "# Function to calculate treatment effect\n",
    "def calculate_ate(data):\n",
    "    \"\"\"Calculate Average Treatment Effect\"\"\"\n",
    "    treated = data[data['X'] == 1]['Y'].mean()\n",
    "    control = data[data['X'] == 0]['Y'].mean()\n",
    "    return treated - control\n",
    "\n",
    "# Observed treatment effect\n",
    "observed_ate = calculate_ate(df_boot)\n",
    "\n",
    "# Bootstrap distribution of ATE\n",
    "bootstrap_ates = []\n",
    "for i in range(n_bootstrap):\n",
    "    # Resample entire dataset with replacement\n",
    "    boot_sample = df_boot.sample(n=len(df_boot), replace=True)\n",
    "    ate = calculate_ate(boot_sample)\n",
    "    bootstrap_ates.append(ate)\n",
    "\n",
    "bootstrap_ates = np.array(bootstrap_ates)\n",
    "\n",
    "# Calculate confidence intervals\n",
    "ci_95 = np.percentile(bootstrap_ates, [2.5, 97.5])\n",
    "ci_99 = np.percentile(bootstrap_ates, [0.5, 99.5])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BOOTSTRAP TREATMENT EFFECT ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nObserved ATE: {observed_ate:.6f}\")\n",
    "print(f\"\\nBootstrap Results ({n_bootstrap} iterations):\")\n",
    "print(f\"  Mean of bootstrap ATEs: {bootstrap_ates.mean():.6f}\")\n",
    "print(f\"  Standard Error: {bootstrap_ates.std():.6f}\")\n",
    "print(f\"  95% Confidence Interval: [{ci_95[0]:.6f}, {ci_95[1]:.6f}]\")\n",
    "print(f\"  99% Confidence Interval: [{ci_99[0]:.6f}, {ci_99[1]:.6f}]\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e82038",
   "metadata": {},
   "source": [
    "## 12. Visualize Bootstrap Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bootstrap distribution\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Subplot 1: Histogram of bootstrap ATEs\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(bootstrap_ates, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "plt.axvline(observed_ate, color='red', linestyle='--', linewidth=2, label=f'Observed ATE: {observed_ate:.4f}')\n",
    "plt.axvline(ci_95[0], color='green', linestyle=':', linewidth=2, label=f'95% CI')\n",
    "plt.axvline(ci_95[1], color='green', linestyle=':', linewidth=2)\n",
    "plt.xlabel('Average Treatment Effect', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title(f'Bootstrap Distribution of ATE\\n({n_bootstrap} iterations)', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Subplot 2: Q-Q plot to check normality\n",
    "plt.subplot(1, 2, 2)\n",
    "from scipy import stats\n",
    "stats.probplot(bootstrap_ates, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot: Bootstrap ATE Distribution', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  • The histogram shows the distribution of treatment effects across bootstrap samples\")\n",
    "print(\"  • The 95% CI tells us the range where the true ATE likely falls\")\n",
    "print(\"  • If 0 is NOT in the CI, the treatment effect is statistically significant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aa1bab",
   "metadata": {},
   "source": [
    "## 13. Bootstrap for Different Statistics\n",
    "\n",
    "Let's explore different statistics beyond the mean (median, variance, correlation, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a88919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap different statistics for Y variable\n",
    "n_boot = 5000\n",
    "np.random.seed(42)\n",
    "\n",
    "statistics = {\n",
    "    'Mean': [],\n",
    "    'Median': [],\n",
    "    'Std Dev': [],\n",
    "    '95th Percentile': []\n",
    "}\n",
    "\n",
    "for i in range(n_boot):\n",
    "    boot_sample = df_boot['Y'].sample(n=len(df_boot['Y']), replace=True)\n",
    "    statistics['Mean'].append(boot_sample.mean())\n",
    "    statistics['Median'].append(boot_sample.median())\n",
    "    statistics['Std Dev'].append(boot_sample.std())\n",
    "    statistics['95th Percentile'].append(boot_sample.quantile(0.95))\n",
    "\n",
    "# Calculate confidence intervals for each statistic\n",
    "print(\"=\" * 70)\n",
    "print(\"BOOTSTRAP RESULTS FOR DIFFERENT STATISTICS (Variable Y)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for stat_name, values in statistics.items():\n",
    "    observed = {\n",
    "        'Mean': df_boot['Y'].mean(),\n",
    "        'Median': df_boot['Y'].median(),\n",
    "        'Std Dev': df_boot['Y'].std(),\n",
    "        '95th Percentile': df_boot['Y'].quantile(0.95)\n",
    "    }[stat_name]\n",
    "    \n",
    "    ci = np.percentile(values, [2.5, 97.5])\n",
    "    \n",
    "    print(f\"\\n{stat_name}:\")\n",
    "    print(f\"  Observed: {observed:.6f}\")\n",
    "    print(f\"  Bootstrap Mean: {np.mean(values):.6f}\")\n",
    "    print(f\"  Bootstrap SE: {np.std(values):.6f}\")\n",
    "    print(f\"  95% CI: [{ci[0]:.6f}, {ci[1]:.6f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503bdfe",
   "metadata": {},
   "source": [
    "## 14. Bootstrap for Correlation Between Y and Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap correlation coefficient\n",
    "n_boot = 5000\n",
    "np.random.seed(42)\n",
    "\n",
    "bootstrap_corrs = []\n",
    "for i in range(n_boot):\n",
    "    # Resample rows (keeping Y and Z pairs together)\n",
    "    indices = np.random.choice(len(df_boot), size=len(df_boot), replace=True)\n",
    "    boot_sample = df_boot.iloc[indices]\n",
    "    corr = boot_sample['Y'].corr(boot_sample['Z'])\n",
    "    bootstrap_corrs.append(corr)\n",
    "\n",
    "bootstrap_corrs = np.array(bootstrap_corrs)\n",
    "\n",
    "# Observed correlation\n",
    "observed_corr = df_boot['Y'].corr(df_boot['Z'])\n",
    "ci_corr = np.percentile(bootstrap_corrs, [2.5, 97.5])\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BOOTSTRAP CORRELATION ANALYSIS: Y vs Z\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nObserved Correlation: {observed_corr:.6f}\")\n",
    "print(f\"Bootstrap Mean: {bootstrap_corrs.mean():.6f}\")\n",
    "print(f\"Bootstrap SE: {bootstrap_corrs.std():.6f}\")\n",
    "print(f\"95% CI: [{ci_corr[0]:.6f}, {ci_corr[1]:.6f}]\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(bootstrap_corrs, bins=50, alpha=0.7, color='coral', edgecolor='black')\n",
    "plt.axvline(observed_corr, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Observed: {observed_corr:.4f}')\n",
    "plt.axvline(ci_corr[0], color='green', linestyle=':', linewidth=2, label='95% CI')\n",
    "plt.axvline(ci_corr[1], color='green', linestyle=':', linewidth=2)\n",
    "plt.axvline(0, color='black', linestyle='-', linewidth=1, alpha=0.5)\n",
    "plt.xlabel('Correlation Coefficient', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Bootstrap Distribution of Correlation (Y vs Z)', fontsize=14)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if ci_corr[0] > 0:\n",
    "    print(\"  ✓ Positive correlation is statistically significant (CI doesn't include 0)\")\n",
    "elif ci_corr[1] < 0:\n",
    "    print(\"  ✓ Negative correlation is statistically significant (CI doesn't include 0)\")\n",
    "else:\n",
    "    print(\"  ✗ Correlation is NOT statistically significant (CI includes 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bce7f6",
   "metadata": {},
   "source": [
    "## 15. Bootstrap Hypothesis Testing\n",
    "\n",
    "Test the null hypothesis that the treatment effect is zero: H₀: ATE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad8531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis test: Is ATE significantly different from 0?\n",
    "print(\"=\" * 70)\n",
    "print(\"BOOTSTRAP HYPOTHESIS TEST\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nH₀: Average Treatment Effect = 0\")\n",
    "print(f\"Hₐ: Average Treatment Effect ≠ 0\")\n",
    "\n",
    "# Two-tailed p-value\n",
    "# Count how many bootstrap samples have ATE as extreme as observed\n",
    "p_value = np.sum(np.abs(bootstrap_ates) >= np.abs(observed_ate)) / n_bootstrap\n",
    "\n",
    "print(f\"\\nObserved ATE: {observed_ate:.6f}\")\n",
    "print(f\"Bootstrap p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.01:\n",
    "    print(f\"\\n✓✓ HIGHLY SIGNIFICANT: Reject H₀ at α=0.01\")\n",
    "    print(f\"   The treatment has a statistically significant effect.\")\n",
    "elif p_value < 0.05:\n",
    "    print(f\"\\n✓ SIGNIFICANT: Reject H₀ at α=0.05\")\n",
    "    print(f\"   The treatment has a statistically significant effect.\")\n",
    "else:\n",
    "    print(f\"\\n✗ NOT SIGNIFICANT: Fail to reject H₀\")\n",
    "    print(f\"   Insufficient evidence that treatment has an effect.\")\n",
    "\n",
    "# Alternative: Check if 0 is in confidence interval\n",
    "ate_in_ci = (ci_95[0] <= 0 <= ci_95[1])\n",
    "print(f\"\\n95% CI contains 0: {ate_in_ci}\")\n",
    "if not ate_in_ci:\n",
    "    print(\"   → This confirms statistical significance\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c25d04",
   "metadata": {},
   "source": [
    "## 16. Bootstrap Summary: Key Concepts and Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7602740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"BOOTSTRAP METHOD - COMPREHENSIVE SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "📚 WHAT IS BOOTSTRAP?\n",
    "   Bootstrap is a resampling method that estimates the sampling distribution\n",
    "   of a statistic by repeatedly drawing samples WITH REPLACEMENT from the data.\n",
    "\n",
    "🔄 HOW IT WORKS:\n",
    "   1. Draw a random sample of size n from the original data (with replacement)\n",
    "   2. Calculate the statistic of interest (mean, median, correlation, etc.)\n",
    "   3. Repeat steps 1-2 many times (typically 1,000-10,000)\n",
    "   4. The distribution of these statistics approximates the sampling distribution\n",
    "\n",
    "✨ ADVANTAGES:\n",
    "   • No assumptions about the underlying distribution (non-parametric)\n",
    "   • Works for complex statistics where formulas don't exist\n",
    "   • Provides confidence intervals and standard errors\n",
    "   • Useful for small samples\n",
    "\n",
    "⚠️ LIMITATIONS:\n",
    "   • Computationally intensive\n",
    "   • Assumes sample is representative of population\n",
    "   • May not work well for extreme values (e.g., max, min)\n",
    "\n",
    "📊 APPLICATIONS IN THIS NOTEBOOK:\n",
    "\"\"\")\n",
    "\n",
    "results_summary = {\n",
    "    \"Treatment Effect (ATE)\": {\n",
    "        \"Estimate\": f\"{observed_ate:.4f}\",\n",
    "        \"95% CI\": f\"[{ci_95[0]:.4f}, {ci_95[1]:.4f}]\",\n",
    "        \"SE\": f\"{bootstrap_ates.std():.4f}\"\n",
    "    },\n",
    "    \"Correlation (Y vs Z)\": {\n",
    "        \"Estimate\": f\"{observed_corr:.4f}\",\n",
    "        \"95% CI\": f\"[{ci_corr[0]:.4f}, {ci_corr[1]:.4f}]\",\n",
    "        \"SE\": f\"{bootstrap_corrs.std():.4f}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for analysis, metrics in results_summary.items():\n",
    "    print(f\"\\n   • {analysis}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"     - {metric}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"🎯 KEY TAKEAWAY\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Bootstrap allows us to quantify uncertainty in our estimates without making\n",
    "strong distributional assumptions. It's particularly valuable when:\n",
    "  • Theoretical formulas for standard errors are unavailable\n",
    "  • The sample size is small or moderate\n",
    "  • The sampling distribution is unknown or non-normal\n",
    "  • We need confidence intervals for complex statistics\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f0cecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size: 50, Variance: 0.0163\n",
      "Sample size: 100, Variance: 0.0116\n",
      "Sample size: 500, Variance: 0.0017\n",
      "Sample size: 1000, Variance: 0.0015\n",
      "Sample size: 5000, Variance: 0.0004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bootstrap_pareto_variance(sample_size, n_bootstrap=1000, shape=2.5):\n",
    "    original_sample = np.random.pareto(shape, sample_size)\n",
    "    bootstrap_means = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        bootstrap_sample = np.random.choice(original_sample, size=sample_size, replace=True)\n",
    "        bootstrap_means.append(np.mean(bootstrap_sample))\n",
    "    \n",
    "    return np.var(bootstrap_means)\n",
    "\n",
    "sample_sizes = [50, 100, 500, 1000, 5000]\n",
    "for size in sample_sizes:\n",
    "    var = bootstrap_pareto_variance(size)\n",
    "    print(f\"Sample size: {size}, Variance: {var:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
